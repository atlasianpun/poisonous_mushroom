{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":76727,"databundleVersionId":9045607,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Basic Packages\nimport numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gc\nimport os\nimport warnings\n\n# Visualization Packages\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom statsmodels.graphics.mosaicplot import mosaic\n\n# Hyperparameter Optimization\nfrom hyperopt import fmin, tpe, hp, Trials, STATUS_OK\nfrom hyperopt.pyll.base import scope\n\n# Scikit-learn Packages\nfrom sklearn.model_selection import train_test_split, GridSearchCV, KFold, StratifiedKFold, RepeatedStratifiedKFold\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, OrdinalEncoder, FunctionTransformer\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import r2_score, roc_auc_score, accuracy_score, matthews_corrcoef, make_scorer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import cross_val_score\n\n\n# Machine Learning Models\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier, Lasso\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, IsolationForest\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\n\nwarnings.filterwarnings('ignore')\ngc.enable()\n%matplotlib inline\n\n#Setting up display options for pandas dataframe\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-20T22:06:57.201476Z","iopub.execute_input":"2024-08-20T22:06:57.201962Z","iopub.status.idle":"2024-08-20T22:07:02.240544Z","shell.execute_reply.started":"2024-08-20T22:06:57.201925Z","shell.execute_reply":"2024-08-20T22:07:02.239572Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"palette = sns.color_palette(\"Spectral\", n_colors=13) \nsns.set_theme(context='notebook', palette=palette, style='darkgrid')\nrs = 101","metadata":{"execution":{"iopub.status.busy":"2024-08-20T22:07:02.242816Z","iopub.execute_input":"2024-08-20T22:07:02.243688Z","iopub.status.idle":"2024-08-20T22:07:02.255618Z","shell.execute_reply.started":"2024-08-20T22:07:02.243648Z","shell.execute_reply":"2024-08-20T22:07:02.254310Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Define a function to identify and replace infrequent categories\ndef replace_infrequent_categories(df, column, threshold=70):\n    value_counts = df[column].value_counts()\n    infrequent = value_counts[value_counts <= threshold].index\n    df[column] = df[column].apply(lambda x: \"Unknown\" if x in infrequent else x)\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-08-20T22:07:02.257011Z","iopub.execute_input":"2024-08-20T22:07:02.257363Z","iopub.status.idle":"2024-08-20T22:07:02.269720Z","shell.execute_reply.started":"2024-08-20T22:07:02.257334Z","shell.execute_reply":"2024-08-20T22:07:02.268619Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/playground-series-s4e8/train.csv')\ndf_test  = pd.read_csv('/kaggle/input/playground-series-s4e8/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-08-20T22:07:02.272166Z","iopub.execute_input":"2024-08-20T22:07:02.272509Z","iopub.status.idle":"2024-08-20T22:07:21.281505Z","shell.execute_reply.started":"2024-08-20T22:07:02.272480Z","shell.execute_reply":"2024-08-20T22:07:21.280239Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Rename the column 'Response' to 'Target' in the DataFrame df_test\ndf_train.rename(columns={'class': 'Target'}, inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T22:07:21.283059Z","iopub.execute_input":"2024-08-20T22:07:21.283428Z","iopub.status.idle":"2024-08-20T22:07:21.297940Z","shell.execute_reply.started":"2024-08-20T22:07:21.283399Z","shell.execute_reply":"2024-08-20T22:07:21.296669Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Create copies of the original DataFrames\ndf_train_cleaned = df_train.copy()\ndf_test_cleaned = df_test.copy()\n\n# Drop 'id' column\ndf_train_cleaned = df_train_cleaned.drop(['id'], axis=1)\n\n# Define the target column\ntarget_column = 'Target'\n\n# Select categorical columns, excluding the target column\ncategorical_columns = df_train_cleaned.select_dtypes(include=['object']).columns.drop(target_column)\n\n# Select numerical columns, excluding the target column if it's numerical\nnumerical_columns = df_train_cleaned.select_dtypes(exclude=['object']).columns.drop(target_column, errors='ignore')\n\n# Print out the lists of columns\nprint(\"Target Column:\", target_column)\nprint(\"\\nCategorical Columns:\", categorical_columns.tolist())\nprint(\"\\nNumerical Columns:\", numerical_columns.tolist())","metadata":{"execution":{"iopub.status.busy":"2024-08-20T22:07:21.299366Z","iopub.execute_input":"2024-08-20T22:07:21.299752Z","iopub.status.idle":"2024-08-20T22:07:23.810069Z","shell.execute_reply.started":"2024-08-20T22:07:21.299723Z","shell.execute_reply":"2024-08-20T22:07:23.808653Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Target Column: Target\n\nCategorical Columns: ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color', 'stem-root', 'stem-surface', 'stem-color', 'veil-type', 'veil-color', 'has-ring', 'ring-type', 'spore-print-color', 'habitat', 'season']\n\nNumerical Columns: ['cap-diameter', 'stem-height', 'stem-width']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Handle invalid values and infrequent categories for all categorical columns\nfor col in categorical_columns:\n    df_train_cleaned = replace_infrequent_categories(df_train_cleaned, col)\n    df_test_cleaned = replace_infrequent_categories(df_test_cleaned, col)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T22:07:23.811687Z","iopub.execute_input":"2024-08-20T22:07:23.812174Z","iopub.status.idle":"2024-08-20T22:11:24.019594Z","shell.execute_reply.started":"2024-08-20T22:07:23.812126Z","shell.execute_reply":"2024-08-20T22:11:24.018262Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(\"The skewness of columns:\")\nprint(df_train_cleaned[numerical_columns].skew())","metadata":{"execution":{"iopub.status.busy":"2024-08-20T22:11:24.021114Z","iopub.execute_input":"2024-08-20T22:11:24.021547Z","iopub.status.idle":"2024-08-20T22:11:24.224036Z","shell.execute_reply.started":"2024-08-20T22:11:24.021509Z","shell.execute_reply":"2024-08-20T22:11:24.222853Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"The skewness of columns:\ncap-diameter    3.972609\nstem-height     1.926682\nstem-width      1.235427\ndtype: float64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Compute medians for numerical columns in the training set\nmedians = df_train_cleaned[numerical_columns].median()\n\n# Fill missing values in the training and testing sets\ndf_train_cleaned[numerical_columns] = df_train_cleaned[numerical_columns].fillna(medians)\ndf_test_cleaned[numerical_columns] = df_test_cleaned[numerical_columns].fillna(medians)\n\nprint(\"As the skewness of all numerical columns is more than 1, we used the median value to fill in any missing values.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-20T22:11:24.225606Z","iopub.execute_input":"2024-08-20T22:11:24.226034Z","iopub.status.idle":"2024-08-20T22:11:24.675636Z","shell.execute_reply.started":"2024-08-20T22:11:24.225992Z","shell.execute_reply":"2024-08-20T22:11:24.674256Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"As the skewness of all numerical columns is more than 1, we used the median value to fill in any missing values.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Impute any missing values with 'Unknown'\ndf_train_cleaned = df_train_cleaned.fillna(\"Unknown\")\ndf_test_cleaned = df_test_cleaned.fillna(\"Unknown\")","metadata":{"execution":{"iopub.status.busy":"2024-08-20T22:11:24.680510Z","iopub.execute_input":"2024-08-20T22:11:24.681161Z","iopub.status.idle":"2024-08-20T22:11:35.515458Z","shell.execute_reply.started":"2024-08-20T22:11:24.681102Z","shell.execute_reply":"2024-08-20T22:11:35.514095Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(\"There are {} duplicates in train dataset.\".format(df_train_cleaned.duplicated().sum()))\nprint(\"There are {} duplicates in test dataset.\".format(df_test_cleaned.duplicated().sum()))","metadata":{"execution":{"iopub.status.busy":"2024-08-20T22:11:35.516902Z","iopub.execute_input":"2024-08-20T22:11:35.517277Z","iopub.status.idle":"2024-08-20T22:11:44.830310Z","shell.execute_reply.started":"2024-08-20T22:11:35.517248Z","shell.execute_reply":"2024-08-20T22:11:44.829053Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"There are 2 duplicates in train dataset.\nThere are 0 duplicates in test dataset.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize LabelEncoder\nlabel_encoder = LabelEncoder()\n\n# Fit and transform the target variable\ntrain_encoded_target = label_encoder.fit_transform(df_train_cleaned[['Target']])\n\n# Convert categorical columns to 'category' dtype \ndf_train_cleaned[categorical_columns] = df_train_cleaned[categorical_columns].astype('category')\ndf_test_cleaned[categorical_columns] = df_test_cleaned[categorical_columns].astype('category')\n\n# Define the numerical pipeline\nnumerical_pipeline = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('convert_to_float32', FunctionTransformer(lambda x: x.astype(np.float32)))\n])\n\n# Define the categorical pipeline\ncategorical_pipeline = Pipeline(steps=[\n    ('ordinal', OrdinalEncoder(dtype=np.int32, handle_unknown='use_encoded_value', unknown_value=-1))\n])\n\n# Combine both numerical and categorical pipelines\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_pipeline, numerical_columns),\n        ('cat', categorical_pipeline, categorical_columns)\n    ]\n)\n\n# Apply the transformations using the pipeline\ndf_train_preprocessed = preprocessor.fit_transform(df_train_cleaned)\ndf_test_preprocessed = preprocessor.transform(df_test_cleaned)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T22:11:44.832277Z","iopub.execute_input":"2024-08-20T22:11:44.832654Z","iopub.status.idle":"2024-08-20T22:12:24.352244Z","shell.execute_reply.started":"2024-08-20T22:11:44.832623Z","shell.execute_reply":"2024-08-20T22:12:24.350968Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Apply Isolation Forest for outlier detection\nisolation_forest = IsolationForest(contamination=0.02, random_state=rs)\noutlier_labels = isolation_forest.fit_predict(df_train_preprocessed)\n\n# Filter out outliers\nnon_outliers_mask = outlier_labels != -1\ndf_train_preprocessed = df_train_preprocessed[non_outliers_mask]\ntrain_encoded_target = train_encoded_target[non_outliers_mask]","metadata":{"execution":{"iopub.status.busy":"2024-08-20T22:12:24.353891Z","iopub.execute_input":"2024-08-20T22:12:24.354338Z","iopub.status.idle":"2024-08-20T22:16:07.000029Z","shell.execute_reply.started":"2024-08-20T22:12:24.354300Z","shell.execute_reply":"2024-08-20T22:16:06.998774Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Separate features (X) and target variable (y)\nX = df_train_preprocessed\ny = train_encoded_target\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T22:16:07.001343Z","iopub.execute_input":"2024-08-20T22:16:07.001683Z","iopub.status.idle":"2024-08-20T22:16:07.007041Z","shell.execute_reply.started":"2024-08-20T22:16:07.001655Z","shell.execute_reply":"2024-08-20T22:16:07.005771Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\n# Assuming X is your feature set and y is your target variable\n\n# Set the desired subset size as a fraction of the original dataset\nsubset_fraction = 0.1  # For example, 20% of the original dataset\n\n# Perform stratified sampling\nX_subset, _,y_subset , _ = train_test_split(X, y, train_size=subset_fraction, stratify=y, random_state=42)\n\n# Now, X_subset and y_subset will have the same class distribution as the original dataset\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T22:16:07.008434Z","iopub.execute_input":"2024-08-20T22:16:07.008790Z","iopub.status.idle":"2024-08-20T22:16:08.759608Z","shell.execute_reply.started":"2024-08-20T22:16:07.008760Z","shell.execute_reply":"2024-08-20T22:16:08.758382Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_subset, y_subset, test_size=0.2, random_state=rs)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T22:16:08.761353Z","iopub.execute_input":"2024-08-20T22:16:08.761740Z","iopub.status.idle":"2024-08-20T22:16:08.807392Z","shell.execute_reply.started":"2024-08-20T22:16:08.761709Z","shell.execute_reply":"2024-08-20T22:16:08.806153Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"mcc_scorer = make_scorer(matthews_corrcoef)\nparam_space = {\n    'n_estimators': scope.int(hp.quniform('n_estimators', 100, 500, 1)),\n    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n    'max_depth': scope.int(hp.quniform('max_depth', 1, 14, 1)),\n    'min_child_weight': scope.int(hp.quniform('min_child_weight', 1, 10, 1)),\n    'subsample': hp.uniform('subsample', 0.5, 0.9),\n    'colsample_bytree': hp.uniform('colsample_bytree', 0.4, 0.8)\n}\n\n# Define the objective function to minimize\ndef objective(params):\n    xgb = XGBClassifier(\n        use_label_encoder=False, \n        eval_metric='mlogloss',\n        n_estimators=int(params['n_estimators']),\n        learning_rate=params['learning_rate'],\n        max_depth=int(params['max_depth']),\n        min_child_weight=int(params['min_child_weight']),\n        subsample=params['subsample'],\n        colsample_bytree=params['colsample_bytree']\n    )\n    \n    # 5-fold cross-validation\n    cv_results = cross_val_score(xgb, X_train, y_train, cv=5, scoring=mcc_scorer, n_jobs=-1)\n    \n    # We aim to maximize MCC, so we minimize the negative MCC\n    return {'loss': -np.mean(cv_results), 'status': STATUS_OK}\n\n# Run Hyperopt\ntrials = Trials()\nbest = fmin(fn=objective, \n            space=param_space, \n            algo=tpe.suggest, \n            max_evals=50, \n            trials=trials)\n\n# Extract the best parameters\nbest_params = {\n    'n_estimators': int(best['n_estimators']),\n    'learning_rate': best['learning_rate'],\n    'max_depth': int(best['max_depth']),\n    'min_child_weight': int(best['min_child_weight']),\n    'subsample': best['subsample'],\n    'colsample_bytree': best['colsample_bytree']\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T22:16:08.809263Z","iopub.execute_input":"2024-08-20T22:16:08.809656Z","iopub.status.idle":"2024-08-20T22:49:25.984333Z","shell.execute_reply.started":"2024-08-20T22:16:08.809625Z","shell.execute_reply":"2024-08-20T22:49:25.983028Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"100%|██████████| 50/50 [33:17<00:00, 39.94s/trial, best loss: -0.9835863405165034]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Best Parameters:\\n\", best_params)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T22:49:25.986197Z","iopub.execute_input":"2024-08-20T22:49:25.986563Z","iopub.status.idle":"2024-08-20T22:49:25.992977Z","shell.execute_reply.started":"2024-08-20T22:49:25.986525Z","shell.execute_reply":"2024-08-20T22:49:25.991739Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Best Parameters:\n {'n_estimators': 252, 'learning_rate': 0.047699446531199105, 'max_depth': 14, 'min_child_weight': 7, 'subsample': 0.7500862527794382, 'colsample_bytree': 0.44307012152489356}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the model with the best parameters\nbest_model = XGBClassifier(\n    use_label_encoder=False, \n    eval_metric='mlogloss',\n    **best_params\n)\nbest_model.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred = best_model.predict(X_test)\n\n# Evaluate the model\nprint(\"Test MCC Score:\", matthews_corrcoef(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-08-20T22:49:25.994329Z","iopub.execute_input":"2024-08-20T22:49:25.994708Z","iopub.status.idle":"2024-08-20T22:49:34.804798Z","shell.execute_reply.started":"2024-08-20T22:49:25.994678Z","shell.execute_reply":"2024-08-20T22:49:34.803708Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Test MCC Score: 0.9832632322870393\n","output_type":"stream"}]},{"cell_type":"code","source":"test_preds = best_model.predict(df_test_preprocessed)\ntest_preds = label_encoder.inverse_transform(test_preds)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:21:17.973012Z","iopub.execute_input":"2024-08-20T23:21:17.973634Z","iopub.status.idle":"2024-08-20T23:21:32.550664Z","shell.execute_reply.started":"2024-08-20T23:21:17.973592Z","shell.execute_reply":"2024-08-20T23:21:32.549587Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'id': df_test['id'],\n                       'class': test_preds})\n\noutput.to_csv('submission.csv', index=False)\n\noutput.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:21:32.552680Z","iopub.execute_input":"2024-08-20T23:21:32.553130Z","iopub.status.idle":"2024-08-20T23:21:35.496106Z","shell.execute_reply.started":"2024-08-20T23:21:32.553089Z","shell.execute_reply":"2024-08-20T23:21:35.494878Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"        id class\n0  3116945     e\n1  3116946     p\n2  3116947     p\n3  3116948     p\n4  3116949     e","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3116945</td>\n      <td>e</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3116946</td>\n      <td>p</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3116947</td>\n      <td>p</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3116948</td>\n      <td>p</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3116949</td>\n      <td>e</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}